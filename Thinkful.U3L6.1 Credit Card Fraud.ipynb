{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import data science environment.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "sns.set_style('white')\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    action='ignore',\n",
    "    module='scipy',\n",
    "    message='internal gelsd'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.360</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>2.536</td>\n",
       "      <td>1.378</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>149.620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.192</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>2.690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.358</td>\n",
       "      <td>-1.340</td>\n",
       "      <td>1.773</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>1.800</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.909</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>378.660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>1.793</td>\n",
       "      <td>-0.863</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>1.247</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-1.387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-1.176</td>\n",
       "      <td>0.647</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.061</td>\n",
       "      <td>123.500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.000</td>\n",
       "      <td>-1.158</td>\n",
       "      <td>0.878</td>\n",
       "      <td>1.549</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.593</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>0.818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.798</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.215</td>\n",
       "      <td>69.990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time     V1     V2    V3     V4     V5     V6     V7     V8     V9  ...    \\\n",
       "0 0.000 -1.360 -0.073 2.536  1.378 -0.338  0.462  0.240  0.099  0.364  ...     \n",
       "1 0.000  1.192  0.266 0.166  0.448  0.060 -0.082 -0.079  0.085 -0.255  ...     \n",
       "2 1.000 -1.358 -1.340 1.773  0.380 -0.503  1.800  0.791  0.248 -1.515  ...     \n",
       "3 1.000 -0.966 -0.185 1.793 -0.863 -0.010  1.247  0.238  0.377 -1.387  ...     \n",
       "4 2.000 -1.158  0.878 1.549  0.403 -0.407  0.096  0.593 -0.271  0.818  ...     \n",
       "\n",
       "     V21    V22    V23    V24    V25    V26    V27    V28  Amount  Class  \n",
       "0 -0.018  0.278 -0.110  0.067  0.129 -0.189  0.134 -0.021 149.620      0  \n",
       "1 -0.226 -0.639  0.101 -0.340  0.167  0.126 -0.009  0.015   2.690      0  \n",
       "2  0.248  0.772  0.909 -0.689 -0.328 -0.139 -0.055 -0.060 378.660      0  \n",
       "3 -0.108  0.005 -0.190 -1.176  0.647 -0.222  0.063  0.061 123.500      0  \n",
       "4 -0.009  0.798 -0.137  0.141 -0.206  0.502  0.219  0.215  69.990      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preview the data file.\n",
    "credit_card = pd.read_csv('creditcard.csv')\n",
    "credit_card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>...</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "      <td>284807.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.860</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>88.350</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.146</td>\n",
       "      <td>1.959</td>\n",
       "      <td>1.651</td>\n",
       "      <td>1.516</td>\n",
       "      <td>1.416</td>\n",
       "      <td>1.380</td>\n",
       "      <td>1.332</td>\n",
       "      <td>1.237</td>\n",
       "      <td>1.194</td>\n",
       "      <td>1.099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.330</td>\n",
       "      <td>250.120</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-56.408</td>\n",
       "      <td>-72.716</td>\n",
       "      <td>-48.326</td>\n",
       "      <td>-5.683</td>\n",
       "      <td>-113.743</td>\n",
       "      <td>-26.161</td>\n",
       "      <td>-43.557</td>\n",
       "      <td>-73.217</td>\n",
       "      <td>-13.434</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830</td>\n",
       "      <td>-10.933</td>\n",
       "      <td>-44.808</td>\n",
       "      <td>-2.837</td>\n",
       "      <td>-10.295</td>\n",
       "      <td>-2.605</td>\n",
       "      <td>-22.566</td>\n",
       "      <td>-15.430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500</td>\n",
       "      <td>-0.920</td>\n",
       "      <td>-0.599</td>\n",
       "      <td>-0.890</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>-0.692</td>\n",
       "      <td>-0.768</td>\n",
       "      <td>-0.554</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>-0.643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>5.600</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011</td>\n",
       "      <td>22.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500</td>\n",
       "      <td>1.316</td>\n",
       "      <td>0.804</td>\n",
       "      <td>1.027</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.078</td>\n",
       "      <td>77.165</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000</td>\n",
       "      <td>2.455</td>\n",
       "      <td>22.058</td>\n",
       "      <td>9.383</td>\n",
       "      <td>16.875</td>\n",
       "      <td>34.802</td>\n",
       "      <td>73.302</td>\n",
       "      <td>120.589</td>\n",
       "      <td>20.007</td>\n",
       "      <td>15.595</td>\n",
       "      <td>...</td>\n",
       "      <td>27.203</td>\n",
       "      <td>10.503</td>\n",
       "      <td>22.528</td>\n",
       "      <td>4.585</td>\n",
       "      <td>7.520</td>\n",
       "      <td>3.517</td>\n",
       "      <td>31.612</td>\n",
       "      <td>33.848</td>\n",
       "      <td>25691.160</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2         V3         V4         V5  \\\n",
       "count 284807.000 284807.000 284807.000 284807.000 284807.000 284807.000   \n",
       "mean   94813.860      0.000      0.000     -0.000      0.000      0.000   \n",
       "std    47488.146      1.959      1.651      1.516      1.416      1.380   \n",
       "min        0.000    -56.408    -72.716    -48.326     -5.683   -113.743   \n",
       "25%    54201.500     -0.920     -0.599     -0.890     -0.849     -0.692   \n",
       "50%    84692.000      0.018      0.065      0.180     -0.020     -0.054   \n",
       "75%   139320.500      1.316      0.804      1.027      0.743      0.612   \n",
       "max   172792.000      2.455     22.058      9.383     16.875     34.802   \n",
       "\n",
       "              V6         V7         V8         V9    ...            V21  \\\n",
       "count 284807.000 284807.000 284807.000 284807.000    ...     284807.000   \n",
       "mean       0.000     -0.000      0.000     -0.000    ...          0.000   \n",
       "std        1.332      1.237      1.194      1.099    ...          0.735   \n",
       "min      -26.161    -43.557    -73.217    -13.434    ...        -34.830   \n",
       "25%       -0.768     -0.554     -0.209     -0.643    ...         -0.228   \n",
       "50%       -0.274      0.040      0.022     -0.051    ...         -0.029   \n",
       "75%        0.399      0.570      0.327      0.597    ...          0.186   \n",
       "max       73.302    120.589     20.007     15.595    ...         27.203   \n",
       "\n",
       "             V22        V23        V24        V25        V26        V27  \\\n",
       "count 284807.000 284807.000 284807.000 284807.000 284807.000 284807.000   \n",
       "mean      -0.000      0.000      0.000      0.000      0.000     -0.000   \n",
       "std        0.726      0.624      0.606      0.521      0.482      0.404   \n",
       "min      -10.933    -44.808     -2.837    -10.295     -2.605    -22.566   \n",
       "25%       -0.542     -0.162     -0.355     -0.317     -0.327     -0.071   \n",
       "50%        0.007     -0.011      0.041      0.017     -0.052      0.001   \n",
       "75%        0.529      0.148      0.440      0.351      0.241      0.091   \n",
       "max       10.503     22.528      4.585      7.520      3.517     31.612   \n",
       "\n",
       "             V28     Amount      Class  \n",
       "count 284807.000 284807.000 284807.000  \n",
       "mean      -0.000     88.350      0.002  \n",
       "std        0.330    250.120      0.042  \n",
       "min      -15.430      0.000      0.000  \n",
       "25%       -0.053      5.600      0.000  \n",
       "50%        0.011     22.000      0.000  \n",
       "75%        0.078     77.165      0.000  \n",
       "max       33.848  25691.160      1.000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View central tendencies.\n",
    "credit_card.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View values counts.\n",
    "sns.countplot('Class', data=credit_card)\n",
    "plt.title('Credit Card Fraud Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wow!  This data set is incredibly imbalanced!  Let's get counts.\n",
    "pd.value_counts(credit_card['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check for any missing data.\n",
    "credit_card.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values, so next we will address the imbalanced classes.  I will up_sample fraudulent values and down_sample the real values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    100000\n",
       "0    100000\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEICAYAAACXo2mmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADi5JREFUeJzt3XGsneVdwPHvvdwW4myrYcW4Sscc2e8PndPW7SK2tGhnKSwWl6idWVDIzEwuSieRKelsQ7Ylc64zy7pI2JDNqJh1LG7Ebk1Uau0gjQtLoLJfBZQmblHKVloSYbT3+Md5u93eXeGc8jvv29v7/fzDe57znJ7nJCXfPu855z1jvV4PSZIqjHe9AEnS+cOoSJLKGBVJUhmjIkkqY1QkSWWMiiSpjFGRJJUxKpKkMkZFklRmousFtG1ycrK3YsWKrpchSfPKoUOHjmbm8pebt+CismLFCu67776ulyFJ80pEPDXIPE9/SZLKGBVJUhmjIkkqY1QkSWWMiiSpjFGRJJUZ2UeKI2IS+FBmro+Iy4F7gB7wKDCVmdMRsR24DjgJbM3MgxVzR/WaJEkvbSQ7lYi4DfgkcFEztBPYlplrgTFgc0SsAtYBk8AWYFfF3FG8HknSYEZ1+usJ4O0zbq8G9jXHe4ANwBpgb2b2MvMIMBERywvmSpI6MpKoZObngBdnDI1lZq85PgEsA5YCz86Yc3r8lc4duRdePNXG02ieORf+XvROvtD1EnQOavPvRVuXaZn5PscS4BhwvDmePf5K547chYsuYPUffKaNp9I88tUP39D1EhibuJAjd7yx62XoHLPyjx9p7bna+vTXwxGxvjneBOwHDgAbI2I8IlYC45l5tGCuJKkjbe1UbgXuiojFwGPA7sw8FRH7gQfpx22qYm5Lr0eSNIeRRSUz/xO4ojk+TP/TW7Pn7AB2zBp7xXMlSd3wy4+SpDJGRZJUxqhIksoYFUlSGaMiSSpjVCRJZYyKJKmMUZEklTEqkqQyRkWSVMaoSJLKGBVJUhmjIkkqY1QkSWWMiiSpjFGRJJUxKpKkMkZFklTGqEiSyhgVSVIZoyJJKmNUJElljIokqYxRkSSVMSqSpDJGRZJUxqhIksoYFUlSGaMiSSpjVCRJZYyKJKmMUZEklTEqkqQyE209UUQsAj4NXAacAn4bOAncA/SAR4GpzJyOiO3Adc39WzPzYERcPujctl6TJOlMbe5UrgUmMvNK4A7gA8BOYFtmrgXGgM0RsQpYB0wCW4BdzeOHmStJ6kCbUTkMTETEOLAUeBFYDexr7t8DbADWAHszs5eZR5rHLB9yriSpA62d/gKeo3/q6+vAq4G3AVdlZq+5/wSwjH5wnpnxuNPjY0PMfXo0L0GS9FLa3Km8B/hyZr4BeBP991cWz7h/CXAMON4czx6fHmKuJKkDbUbl28CzzfG3gEXAwxGxvhnbBOwHDgAbI2I8IlYC45l5dMi5kqQOtHn666PA3RGxn/4O5XbgX4G7ImIx8BiwOzNPNXMepB+9qebxtw4xV5LUgdaikpnPAb82x13r5pi7A9gxa+zwoHMlSd3wy4+SpDJGRZJUxqhIksoYFUlSGaMiSSpjVCRJZYyKJKmMUZEklTEqkqQyRkWSVMaoSJLKGBVJUhmjIkkqY1QkSWWMiiSpjFGRJJUxKpKkMkZFklTGqEiSyhgVSVIZoyJJKmNUJElljIokqYxRkSSVMSqSpDJGRZJUxqhIksoYFUlSGaMiSSpjVCRJZYyKJKmMUZEklTEqkqQyE20+WUT8EfDLwGLgE8A+4B6gBzwKTGXmdERsB64DTgJbM/NgRFw+6Nw2X5Mk6Xta26lExHrgSuDngXXApcBOYFtmrgXGgM0Rsaq5fxLYAuxq/ohh5kqSOtDm6a+NwCPA54EvAvcDq+nvVgD2ABuANcDezOxl5hFgIiKWDzlXktSBNk9/vRp4LfA24HXAF4DxzOw1958AlgFLgWdmPO70+NgQc58e0WuQJL2ENqPyDPD1zPwOkBHxPP1TYKctAY4Bx5vj2ePTQ8yVJHWgzdNf/wJcExFjEfEa4FXAPzTvtQBsAvYDB4CNETEeESvp72aOAg8PMVeS1IHWdiqZeX9EXAUcpB+zKeA/gLsiYjHwGLA7M09FxH7gwRnzAG4dYq4kqQOtfqQ4M2+bY3jdHPN2ADtmjR0edK4kqRt++VGSVGagqETEu2bd/r3RLEeSNJ+95OmviHgH/W/AXx0Rv9AMXwD8JPCxEa9NkjTPvNx7Kl8CvglcDNzZjE0DT4xyUZKk+eklo5KZ3wYeAB6IiEuAiwZ5nCRpYRooDhGxi/5FG79B/7pbPfrX8ZIk6bsG3XFMAj+emdMvO1OStGAN+pHix/neqS9JkuY06E5lJfBURDze3O5lpqe/JElnGDQq7xjpKiRJ54VBo/Kbc4zdUbkQSdL8N2hU/rv57xiwCi/vIkmaw0BRycw7Z96OiD2jWY4kaT4b9Hsqb5hx80fp/4KjJElnGPT018ydyvP0f9tEkqQzDHr66+qIuBh4PfCkv64oSZrLoJe+/1XgK8DtwEMR8c6RrkqSNC8N+imu3wdWZ+b1wM8At4xuSZKk+WrQqExn5nMAmXmC/vsqkiSdYdA36p+MiI8A/wysxd9TkSTNYdCdyp3At4C3AjcCHx/ZiiRJ89agUfkocG9m3gy8Gdg5uiVJkuarQaPyYmY+AZCZT9L/SWFJks4w6HsqT0XEB4EHgbcA/zW6JUmS5qtBdyo3Av8DXAs8Ddw0shVJkuatQb9R/zzwZyNeiyRpnvMS9pKkMkZFklTGqEiSyhgVSVIZoyJJKmNUJElljIokqYxRkSSVGfQyLWUi4hLgq/SveHwSuAfoAY8CU5k5HRHbgeua+7dm5sGIuHzQuS2/JElSo9WdSkQson8Z/f9thnYC2zJzLTAGbI6IVcA6YBLYAuw6i7mSpA60ffrrT4E/B77R3F4N7GuO9wAbgDXA3szsZeYRYCIilg85V5LUgdaiEhG/BTydmV+eMTyWmb3m+ASwDFgKPDtjzunxYeZKkjrQ5nsqNwG9iNgA/DTwGeCSGfcvAY4Bx5vj2ePTQ8yVJHWgtZ1KZl6Vmesycz3wNeAGYE9ErG+mbAL2AweAjRExHhErgfHMPAo8PMRcSVIHWv/01yy3AndFxGLgMWB3Zp6KiP30fxBsHJg6i7mSpA50EpVmt3Laujnu3wHsmDV2eNC5kqRu+OVHSVIZoyJJKmNUJElljIokqYxRkSSVMSqSpDJGRZJUxqhIksoYFUlSGaMiSSpjVCRJZYyKJKmMUZEklTEqkqQyRkWSVMaoSJLKGBVJUhmjIkkqY1QkSWWMiiSpjFGRJJUxKpKkMkZFklTGqEiSyhgVSVIZoyJJKmNUJElljIokqYxRkSSVMSqSpDJGRZJUxqhIksoYFUlSmYm2nigiFgF3A5cBFwLvB/4NuAfoAY8CU5k5HRHbgeuAk8DWzDwYEZcPOret1yRJOlObO5V3As9k5lrgGuDjwE5gWzM2BmyOiFXAOmAS2ALsah4/zFxJUgfajMpngfc1x2P0dxargX3N2B5gA7AG2JuZvcw8AkxExPIh50qSOtBaVDLzucw8ERFLgN3ANmAsM3vNlBPAMmAp8OyMh54eH2auJKkDrb5RHxGXAv8E/GVm/jUwPePuJcAx4HhzPHt8mLmSpA60FpWI+BFgL/DezLy7GX44ItY3x5uA/cABYGNEjEfESmA8M48OOVeS1IHWPv0F3A78MPC+iDj93sotwMciYjHwGLA7M09FxH7gQfrRm2rm3grcNeBcSVIHWotKZt5CPyKzrZtj7g5gx6yxw4POlSR1wy8/SpLKGBVJUhmjIkkqY1QkSWWMiiSpjFGRJJUxKpKkMkZFklTGqEiSyhgVSVIZoyJJKmNUJElljIokqYxRkSSVMSqSpDJGRZJUxqhIksoYFUlSGaMiSSpjVCRJZYyKJKmMUZEklTEqkqQyRkWSVMaoSJLKGBVJUhmjIkkqY1QkSWWMiiSpjFGRJJUxKpKkMkZFklTGqEiSyhgVSVKZia4X8EpFxDjwCeBNwAvAuzLz8W5XJUkL0/mwU7keuCgzfw74Q+AjHa9Hkhas8yEqa4AvAWTmQ8DPdrscSVq45v3pL2Ap8OyM26ciYiIzT841+dChQ0cj4ql2lqaFJL7wga6XIM3tr6LiT3ntIJPOh6gcB5bMuD3+/wUFIDOXj35JkrQwnQ+nvw4A1wJExBXAI90uR5IWrvNhp/J54K0R8RVgDLix4/VI0oI11uv1ul6DJOk8cT6c/pIknSOMiiSpzPnwnoo64JUMdK6LiEngQ5m5vuu1LCTuVHS2vJKBzlkRcRvwSeCirtey0BgVnS2vZKBz2RPA27texEJkVHS25rySQVeLkWbKzM8BL3a9joXIqOhsDXUlA0kLg1HR2fJKBpK+j6crdLa8koGk7+M36iVJZTz9JUkqY1QkSWWMiiSpjFGRJJUxKpKkMn6kWBqxiPgJ4E+AHwB+EPh74AHg3Zm5pcOlSeXcqUgjFBE/BNwLbM3Mq4ErgDcC0enCpBFxpyKN1mbgHzPz3wEy81RE3ABcCawHiIib6V/88FXAUeBXgMuAvwBO0v/H328AzwN/29y+CPidzPxai69FelnuVKTReg3w5MyBzHwO+A5893dpLgY2ZOYk/X/ovRl4K3AQ2ABsB5YBbwGeATYBU/QjJJ1TjIo0Wk8Bl84ciIjXAVcBZOY0/cD8TUR8CvgxYBHwKeAY/Z8XuJn+jmUP/Wuu/R1wBzDdzkuQBmdUpNG6H7gmIl4PEBGLgJ30T3MRET8FXJ+Zvw78Lv3/J8fonzbbn5m/CHwWeC/902XfzMxfAt4PfLDdlyK9PK/9JY1YRKwGPkw/GEuALwL7gHcDN9EPz4XN9Bfo71IeAj5NfxdzAfAe+ruee+nvZCaAOzJzb2svRBqAUZEklfH0lySpjFGRJJUxKpKkMkZFklTGqEiSyhgVSVIZoyJJKmNUJEll/g80HkX2lk/BswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes.\n",
    "cc_real = credit_card[credit_card.Class==0]\n",
    "cc_fraud = credit_card[credit_card.Class==1]\n",
    "\n",
    "# Upsample minority class.\n",
    "cc_fraud_upsampled = resample(cc_fraud,\n",
    "                              replace=True,\n",
    "                              n_samples=100000,\n",
    "                              random_state=15)\n",
    "\n",
    "# Downsample majority class.\n",
    "cc_real_downsampled = resample(cc_real,\n",
    "                               replace=False,\n",
    "                               n_samples=100000,\n",
    "                               random_state=15)\n",
    "\n",
    "# Combine upsampled minority class and downsampled majority class.\n",
    "cc_sampled = pd.concat([cc_real_downsampled, cc_fraud_upsampled])\n",
    "\n",
    "# Display new class counts.\n",
    "sns.countplot(x='Class', data=cc_sampled)\n",
    "cc_sampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>87790.370</td>\n",
       "      <td>-2.391</td>\n",
       "      <td>1.821</td>\n",
       "      <td>-3.520</td>\n",
       "      <td>2.268</td>\n",
       "      <td>-1.582</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>-2.797</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.038</td>\n",
       "      <td>104.267</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48121.988</td>\n",
       "      <td>5.537</td>\n",
       "      <td>3.712</td>\n",
       "      <td>6.236</td>\n",
       "      <td>3.204</td>\n",
       "      <td>4.233</td>\n",
       "      <td>1.759</td>\n",
       "      <td>5.873</td>\n",
       "      <td>4.861</td>\n",
       "      <td>2.321</td>\n",
       "      <td>...</td>\n",
       "      <td>2.786</td>\n",
       "      <td>1.171</td>\n",
       "      <td>1.194</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.477</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.448</td>\n",
       "      <td>251.059</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-46.855</td>\n",
       "      <td>-60.465</td>\n",
       "      <td>-32.965</td>\n",
       "      <td>-5.683</td>\n",
       "      <td>-40.428</td>\n",
       "      <td>-17.575</td>\n",
       "      <td>-43.557</td>\n",
       "      <td>-73.217</td>\n",
       "      <td>-13.434</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830</td>\n",
       "      <td>-9.499</td>\n",
       "      <td>-44.808</td>\n",
       "      <td>-2.823</td>\n",
       "      <td>-10.295</td>\n",
       "      <td>-2.605</td>\n",
       "      <td>-9.846</td>\n",
       "      <td>-8.314</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46057.000</td>\n",
       "      <td>-2.867</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-5.118</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.797</td>\n",
       "      <td>-1.575</td>\n",
       "      <td>-3.105</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-2.330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>1.290</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80501.500</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>0.963</td>\n",
       "      <td>-1.367</td>\n",
       "      <td>1.320</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>-0.647</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.035</td>\n",
       "      <td>18.400</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>134551.500</td>\n",
       "      <td>1.037</td>\n",
       "      <td>2.829</td>\n",
       "      <td>0.346</td>\n",
       "      <td>4.243</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.219</td>\n",
       "      <td>99.990</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172783.000</td>\n",
       "      <td>2.420</td>\n",
       "      <td>22.058</td>\n",
       "      <td>4.188</td>\n",
       "      <td>16.875</td>\n",
       "      <td>24.656</td>\n",
       "      <td>23.918</td>\n",
       "      <td>44.054</td>\n",
       "      <td>20.007</td>\n",
       "      <td>10.393</td>\n",
       "      <td>...</td>\n",
       "      <td>27.203</td>\n",
       "      <td>10.503</td>\n",
       "      <td>18.947</td>\n",
       "      <td>3.712</td>\n",
       "      <td>5.852</td>\n",
       "      <td>3.517</td>\n",
       "      <td>12.152</td>\n",
       "      <td>15.942</td>\n",
       "      <td>18910.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2         V3         V4         V5  \\\n",
       "count 200000.000 200000.000 200000.000 200000.000 200000.000 200000.000   \n",
       "mean   87790.370     -2.391      1.821     -3.520      2.268     -1.582   \n",
       "std    48121.988      5.537      3.712      6.236      3.204      4.233   \n",
       "min        0.000    -46.855    -60.465    -32.965     -5.683    -40.428   \n",
       "25%    46057.000     -2.867     -0.140     -5.118     -0.107     -1.797   \n",
       "50%    80501.500     -0.781      0.963     -1.367      1.320     -0.430   \n",
       "75%   134551.500      1.037      2.829      0.346      4.243      0.475   \n",
       "max   172783.000      2.420     22.058      4.188     16.875     24.656   \n",
       "\n",
       "              V6         V7         V8         V9    ...            V21  \\\n",
       "count 200000.000 200000.000 200000.000 200000.000    ...     200000.000   \n",
       "mean      -0.699     -2.797      0.297     -1.295    ...          0.355   \n",
       "std        1.759      5.873      4.861      2.321    ...          2.786   \n",
       "min      -17.575    -43.557    -73.217    -13.434    ...        -34.830   \n",
       "25%       -1.575     -3.105     -0.203     -2.330    ...         -0.171   \n",
       "50%       -0.647     -0.649      0.158     -0.715    ...          0.149   \n",
       "75%        0.080      0.268      0.877      0.167    ...          0.653   \n",
       "max       23.918     44.054     20.007     10.393    ...         27.203   \n",
       "\n",
       "             V22        V23        V24        V25        V26        V27  \\\n",
       "count 200000.000 200000.000 200000.000 200000.000 200000.000 200000.000   \n",
       "mean       0.010     -0.024     -0.052      0.020      0.026      0.084   \n",
       "std        1.171      1.194      0.564      0.673      0.477      1.016   \n",
       "min       -9.499    -44.808     -2.823    -10.295     -2.605     -9.846   \n",
       "25%       -0.538     -0.239     -0.401     -0.318     -0.289     -0.063   \n",
       "50%        0.030     -0.033      0.007      0.050     -0.015      0.050   \n",
       "75%        0.579      0.192      0.375      0.390      0.324      0.455   \n",
       "max       10.503     18.947      3.712      5.852      3.517     12.152   \n",
       "\n",
       "             V28     Amount      Class  \n",
       "count 200000.000 200000.000 200000.000  \n",
       "mean       0.038    104.267      0.500  \n",
       "std        0.448    251.059      0.500  \n",
       "min       -8.314      0.000      0.000  \n",
       "25%       -0.059      1.290      0.000  \n",
       "50%        0.035     18.400      0.500  \n",
       "75%        0.219     99.990      1.000  \n",
       "max       15.942  18910.000      1.000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_sampled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10e95bb00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cc_sampled.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into classes and training groups.\n",
    "X = cc_sampled.drop(['Class'], 1)\n",
    "y = cc_sampled.Class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "[0.8641  0.86415 0.86685 0.86295 0.8624  0.86195 0.86775 0.86805 0.86735\n",
      " 0.8601 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88     25118\n",
      "           1       0.99      0.75      0.85     24882\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     50000\n",
      "   macro avg       0.89      0.87      0.87     50000\n",
      "weighted avg       0.89      0.87      0.87     50000\n",
      "\n",
      "[[24880   238]\n",
      " [ 6329 18553]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes.\n",
    "gnb = GaussianNB()\n",
    "# Fit the model.\n",
    "gnb.fit(X_train, y_train)\n",
    "print(gnb)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "# Accuracy score.\n",
    "accuracy_score(y_test, y_pred_gnb)\n",
    "# Cross-validation.\n",
    "gnb_score = cross_val_score(gnb, X, y, cv=10)\n",
    "print(gnb_score)\n",
    "# Classification report.\n",
    "print(classification_report(y_test, y_pred_gnb))\n",
    "# Confusion matrix.\n",
    "print(confusion_matrix(y_test, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "[0.9963  0.99715 0.9966  0.9968  0.99725 0.99655 0.99675 0.9971  0.99685\n",
      " 0.9971 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     25118\n",
      "           1       0.99      1.00      1.00     24882\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     50000\n",
      "   macro avg       1.00      1.00      1.00     50000\n",
      "weighted avg       1.00      1.00      1.00     50000\n",
      "\n",
      "[[24918   200]\n",
      " [    0 24882]]\n"
     ]
    }
   ],
   "source": [
    "# Build KNN model.\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "# Fit the model.\n",
    "knn.fit(X_train, y_train)\n",
    "print(knn)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "# Accuracy score.\n",
    "accuracy_score(y_test, y_pred_knn)\n",
    "# Cross-validation.\n",
    "knn_score = cross_val_score(knn, X, y, cv=10)\n",
    "print(knn_score)\n",
    "# Classification report.\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "# Confusion matrix.\n",
    "print(confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
      "            max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=15, splitter='best')\n",
      "[0.89745 0.8952  0.90175 0.89625 0.89635 0.89455 0.8936  0.89775 0.896\n",
      " 0.89375]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     25118\n",
      "           1       0.90      0.89      0.90     24882\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     50000\n",
      "   macro avg       0.90      0.90      0.90     50000\n",
      "weighted avg       0.90      0.90      0.90     50000\n",
      "\n",
      "[[22647  2471]\n",
      " [ 2630 22252]]\n"
     ]
    }
   ],
   "source": [
    "# Build the Decision Tree model.\n",
    "# Import tools.\n",
    "from sklearn import tree\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_features=1,\n",
    "    max_depth=4,\n",
    "    random_state=15\n",
    ")\n",
    "# Fit the model.\n",
    "dtc.fit(X_train, y_train)\n",
    "print(dtc)\n",
    "y_pred_dtc = dtc.predict(X_test)\n",
    "# Accuracy score.\n",
    "accuracy_score(y_test, y_pred_dtc)\n",
    "# Cross-validation.\n",
    "dtc_score = cross_val_score(dtc, X, y, cv=10)\n",
    "print(dtc_score)\n",
    "# Classification report.\n",
    "print(classification_report(y_test, y_pred_dtc))\n",
    "# Confusion matrix.\n",
    "print(confusion_matrix(y_test, y_pred_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "[0.99995 0.99985 0.99995 0.99995 0.99985 0.99995 1.      0.9999  0.99995\n",
      " 0.99995]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     25118\n",
      "           1       1.00      1.00      1.00     24882\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     50000\n",
      "   macro avg       1.00      1.00      1.00     50000\n",
      "weighted avg       1.00      1.00      1.00     50000\n",
      "\n",
      "[[25113     5]\n",
      " [    0 24882]]\n"
     ]
    }
   ],
   "source": [
    "# Build the Random Forest model.\n",
    "# Import tools.\n",
    "from sklearn import ensemble\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "# Fit the model.\n",
    "rfc.fit(X_train, y_train)\n",
    "print(rfc)\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "# Accuracy score.\n",
    "accuracy_score(y_test, y_pred_rfc)\n",
    "# Cross-validation.\n",
    "rfc_score = cross_val_score(rfc, X, y, cv=10)\n",
    "print(rfc_score)\n",
    "# Classification report.\n",
    "print(classification_report(y_test, y_pred_rfc))\n",
    "# Confusion matrix.\n",
    "print(confusion_matrix(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
      "          solver='warn', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93695 0.93665 0.94595 0.93335 0.93685 0.9378  0.9398  0.9373  0.939\n",
      " 0.9376 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     25118\n",
      "           1       0.97      0.92      0.94     24882\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     50000\n",
      "   macro avg       0.95      0.95      0.95     50000\n",
      "weighted avg       0.95      0.95      0.95     50000\n",
      "\n",
      "[[24335   783]\n",
      " [ 1896 22986]]\n"
     ]
    }
   ],
   "source": [
    "# Build the Logistic Regression model.\n",
    "lr = LogisticRegression(C=1e9)\n",
    "# Fit the model.\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "# Accuracy score,\n",
    "accuracy_score(y_test, y_pred_lr)\n",
    "# Cross-validation.\n",
    "lr_score = cross_val_score(lr, X, y, cv=10)\n",
    "print(lr_score)\n",
    "# Classification report.\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "# Confusion matrix.\n",
    "print(confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78865 0.54515 0.87905 0.88935 0.9003  0.8881  0.8959  0.8972  0.8919\n",
      " 0.87915]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     25118\n",
      "           1       0.94      0.84      0.89     24882\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     50000\n",
      "   macro avg       0.90      0.89      0.89     50000\n",
      "weighted avg       0.90      0.90      0.89     50000\n",
      "\n",
      "[[23900  1218]\n",
      " [ 4031 20851]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Build the SVC model.\n",
    "svc = LinearSVC()\n",
    "# Fit the model.\n",
    "svc.fit(X_train, y_train)\n",
    "print(svc)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "# Accuracy score.\n",
    "accuracy_score(y_test, y_pred_svc)\n",
    "# Cross-validation.\n",
    "svc_score = cross_val_score(svc, X, y, cv=10)\n",
    "print(svc_score)\n",
    "# Classification score.\n",
    "print(classification_report(y_test, y_pred_svc))\n",
    "# Confusion matrix.\n",
    "print(confusion_matrix(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "[0.9947  0.9927  0.9926  0.99205 0.99285 0.995   0.9937  0.9927  0.99455\n",
      " 0.9928 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     25118\n",
      "           1       0.99      0.99      0.99     24882\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     50000\n",
      "   macro avg       0.99      0.99      0.99     50000\n",
      "weighted avg       0.99      0.99      0.99     50000\n",
      "\n",
      "[[24917   201]\n",
      " [  195 24687]]\n"
     ]
    }
   ],
   "source": [
    "# Build the Gradient Boosting model.\n",
    "gbm = ensemble.GradientBoostingClassifier()\n",
    "# Fit the model.\n",
    "gbm.fit(X_train, y_train)\n",
    "print(gbm)\n",
    "y_pred_gbm = gbm.predict(X_test)\n",
    "# Accuracy score.\n",
    "accuracy_score(y_test, y_pred_gbm)\n",
    "# Cross-validation.\n",
    "gbm_score = cross_val_score(gbm, X, y, cv=10)\n",
    "print(gbm_score)\n",
    "# Classification report.\n",
    "print(classification_report(y_test, y_pred_gbm))\n",
    "# Confusion matrix.\n",
    "print(confusion_matrix(y_test, y_pred_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
